name: Ollama with Cloudflared Tunnel

on:
  workflow_dispatch: # run manually
  push:
    branches:
      - main

jobs:
  run-ollama:
    runs-on: ubuntu-latest
    steps:
      # Checkout repo
      - name: Checkout code
        uses: actions/checkout@v3

      # Install Ollama
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          # Start Ollama on custom port 11500, binding to 0.0.0.0
          nohup ollama serve --host 0.0.0.0:11500 > ollama.log 2>&1 &
          sleep 10

      # Pull Qwen3 model
      - name: Pull Qwen3 model
        run: |
          ollama pull qwen3:0.6b

      # Run test prompt
      - name: Test Ollama prompt
        run: |
          curl http://127.0.0.1:11500/api/generate \
            -d '{"model": "qwen3:0.6b", "prompt": "hey there how are you"}' \
            -H "Content-Type: application/json"

      # Install cloudflared
      - name: Install Cloudflared
        run: |
          wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
          sudo dpkg -i cloudflared-linux-amd64.deb

      # Start Cloudflared tunnel
      - name: Start Cloudflared Tunnel
        run: |
          nohup cloudflared tunnel --url http://0.0.0.0:11500 > cloudflared.log 2>&1 &
          sleep 10
          echo "Tunnel URL:"
          grep -o 'https://.*trycloudflare.com' cloudflared.log | head -n 1 | tee tunnel_url.txt
          echo "Try API endpoint: $(cat tunnel_url.txt)/api/tags"
          echo "Try API generate: $(cat tunnel_url.txt)/api/generate"

      # Keep job alive for 10 minutes
      - name: Keep alive for 10 minutes
        run: |
          echo "Keeping Ollama + Cloudflared alive for 10 minutes..."
          sleep 600
